{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "import cv2 import numpy as np from tensorflow.keras.models import\n",
    "load_model from tensorflow.keras.preprocessing import image\n",
    "\n",
    "class Video(object): def **init**(self): self.video =\n",
    "cv2.VideoCapture(0) self.roi_start = (50, 150) self.roi_end = (250, 350)\n",
    "self.model = load_model(‘asl_model.h5’) \\# Execute Local Trained Model\n",
    "\\# self.model = load_model(‘IBM_Communication_Model.h5’) \\# Execute IBM\n",
    "Trained Model self.index=\\[‘A’,‘B’,‘C’,‘D’,‘E’,‘F’,‘G’,‘H’,‘I’\\] self.y\n",
    "= None def **del**(self): self.video.release() def get_frame(self):\n",
    "ret,frame = self.video.read() frame = cv2.resize(frame, (640, 480)) copy\n",
    "= frame.copy() copy = copy\\[150:150+200,50:50+200\\] \\# Prediction Start\n",
    "cv2.imwrite(‘image.jpg’,copy) copy_img = image.load_img(‘image.jpg’,\n",
    "target_size=(64,64)) x = image.img_to_array(copy_img) x =\n",
    "np.expand_dims(x, axis=0) pred = np.argmax(self.model.predict(x),\n",
    "axis=1) self.y = pred\\[0\\] cv2.putText(frame,‘The Predicted Alphabet\n",
    "is:’+str(self.index\\[self.y\\]),(100,50),cv2.FONT_HERSHEY_SIMPLEX,1,(0,0,0),3)\n",
    "ret,jpg = cv2.imencode(‘.jpg’, frame) return jpg.tobytes()"
   ]
  }
 ],
 "nbformat": 4,
 "nbformat_minor": 5,
 "metadata": {}
}
